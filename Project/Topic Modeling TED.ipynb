{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data files were taken from https://www.kaggle.com/rounakbanik/ted-talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import nltk, re, pickle, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, wordpunct_tokenize, MWETokenizer\n",
    "from nltk.stem import porter, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD, NMF\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_main = pd.read_csv('data/ted_main.csv')\n",
    "ted_trans = pd.read_csv('data/transcripts.csv')    \n",
    "ted_all = pd.merge(ted_trans,right=ted_main,on='url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2467\n",
      "2467\n"
     ]
    }
   ],
   "source": [
    "ted_all['id'] = ted_all.index\n",
    "print(len(ted_all))\n",
    "talks = ted_all['transcript']\n",
    "print(len(talks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    lemmizer = WordNetLemmatizer()\n",
    "\n",
    "    stop = stopwords.words('english')\n",
    "    stop += ['.', ',',':','...','!\"','?\"', \"'\", '\"',' - ',' — ',',\"','.\"','!', ';','♫♫','♫','ca','em','mr','000','yes'\\\n",
    "             '.\\'\"','[',']','—',\".\\'\", 'ok','okay','yeah','ya','stuff', ' 000 ',' em ',\"ll\",\"didn\",'bg','looking'\\\n",
    "             ' oh ','thank','thanks','la','was','wa','?','like','go',' le ',' ca ',' I ',\" ? \",\"s\", \" t \",\"ve\",\"re\"]\n",
    "\n",
    "    cleaned_text = []\n",
    "    \n",
    "    for post in text:\n",
    "        cleaned_words = []\n",
    "        \n",
    "        # remove parentheticals\n",
    "        clean_parens = re.sub(r'\\([^)]*\\)', ' ', post)\n",
    "        \n",
    "        for word  in wordpunct_tokenize(clean_parens):  \n",
    "            \n",
    "            if word.lower() not in stop:\n",
    "                low_word = lemmizer.lemmatize(word)    \n",
    "\n",
    "                if low_word.lower() not in stop: \n",
    "\n",
    "                    cleaned_words.append(low_word.lower())\n",
    "   \n",
    "        cleaned_text.append(' '.join(cleaned_words))\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data in 65.835s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "cleaned_talks = clean_text(talks)\n",
    "print(\"Cleaned data in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_mod_lda(data,topics=5,iters=10,ngram_min=1, ngram_max=3, max_df=0.6, max_feats=5000):\n",
    "    \n",
    "    vectorizer = CountVectorizer(ngram_range=(ngram_min,ngram_max), \n",
    "                             stop_words='english', \n",
    "                             max_df = max_df, \n",
    "                             max_features=max_feats)\n",
    "\n",
    "    vect_data = vectorizer.fit_transform(data)\n",
    "    lda = LatentDirichletAllocation(n_components=topics,\n",
    "                                    max_iter=iters,\n",
    "                                    random_state=42,\n",
    "                                    learning_method='online',\n",
    "                                    n_jobs=-1)\n",
    "    \n",
    "    lda_dat = lda.fit_transform(vect_data)\n",
    "    \n",
    "    def display_topics(model, feature_names, no_top_words):\n",
    "        for ix, topic in enumerate(model.components_):\n",
    "            print(\"Topic \", ix)\n",
    "            print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "    \n",
    "    display_topics(lda, vectorizer.get_feature_names(),20)\n",
    "    \n",
    "    return vectorizer, vect_data, lda, lda_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic  0\n",
      "water ocean fish sea coral plastic boat animal whale light marine blue bottle oil ship swim specie area deep river\n",
      "Topic  1\n",
      "word language book god religion story culture century knowledge compassion english history religious believe course read consciousness identity self tradition\n",
      "Topic  2\n",
      "gene dna disease virus genome molecule genetic bacteria cell vaccine organism million hiv biology probably case technology malaria protein understand\n",
      "Topic  3\n",
      "story love guy old man wanted feel friend told took home night oh moment later happened away remember knew week\n",
      "Topic  4\n",
      "art sound music play sort image piece object hand eye body artist video experience create color looking film real mind\n",
      "Topic  5\n",
      "kid school student game teacher education learning child learn high play percent teach class video number answer course getting high school\n",
      "Topic  6\n",
      "earth planet foot ice mars water air space fly surface mile cloud meter atmosphere shark sun satellite temperature moon mountain\n",
      "Topic  7\n",
      "city building design project space community built street build new york york create house public architecture material home live neighborhood center\n",
      "Topic  8\n",
      "medium internet online page choice book photo image google picture twitter read video facebook content story site news blog email\n",
      "Topic  9\n",
      "woman child men family girl young school mother black parent boy community man home father sex kid story old white\n",
      "Topic  10\n",
      "robot rule worker ant colony build collective interaction intelligence create task working behavior pattern factory group engineer example building motion\n",
      "Topic  11\n",
      "cell cancer body drug blood patient tissue disease tumor stem sugar organ breast heart stem cell surgery medicine bone type lung\n",
      "Topic  12\n",
      "car percent energy billion cost million oil climate power dollar technology le carbon future fuel 10 nuclear solution country growth\n",
      "Topic  13\n",
      "data technology computer information machine phone using device digital network internet example algorithm tool web software build code real sort\n",
      "Topic  14\n",
      "country government africa war global united percent state states united states china political india million society power public economic democracy citizen\n",
      "Topic  15\n",
      "brain health patient care doctor medical study disease baby hospital child percent neuron treatment body memory mental heart research sleep\n",
      "Topic  16\n",
      "social feel experience love society self relationship group person thinking live mind future conversation understand reason value example sense power\n",
      "Topic  17\n",
      "animal food specie plant tree forest nature eat bee insect monkey grow soil natural land africa creature million male dog\n",
      "Topic  18\n",
      "company money business dollar market product value pay buy industry organization job 10 cost decision example making financial service success\n",
      "Topic  19\n",
      "universe light science star space theory planet physic particle galaxy number earth energy matter hole black billion telescope dark sun\n",
      "\n",
      "LDA done in 261.755s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "vect_mod, vect_data, lda_mod, lda_data = topic_mod_lda(cleaned_talks,\n",
    "                                                       topics=20,\n",
    "                                                       iters=50,\n",
    "                                                       ngram_min=1, \n",
    "                                                       ngram_max=2, \n",
    "                                                       max_df=0.5, \n",
    "                                                       max_feats=2000)\n",
    "print(\"\\nLDA done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_mod_nmf(data, topics=5,iters=10,ngram_min=1, ngram_max=3, max_df=0.6, max_feats=5000):\n",
    "      \n",
    "    vectorizer = CountVectorizer(ngram_range=(ngram_min,ngram_max), \n",
    "                             stop_words='english', \n",
    "                             max_df = max_df, \n",
    "                             max_features=max_feats)\n",
    "    \n",
    "    vect_data = vectorizer.fit_transform(data)\n",
    "    nmf = NMF(n_components=topics, max_iter=iters, random_state=42)\n",
    "    nmf_dat = nmf.fit_transform(vect_data)\n",
    "    \n",
    "    def display_topics(model_, feature_names, no_top_words):\n",
    "        for ix, topic in enumerate(model_.components_):\n",
    "            print(\"Topic \", ix)\n",
    "            print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "    \n",
    "    display_topics(nmf, vectorizer.get_feature_names(),20)\n",
    "    \n",
    "    return vectorizer, vect_data, nmf, nmf_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic  0\n",
      "love feel person guy man experience god friend old word hand wanted moment mind sort believe maybe looking thinking feeling\n",
      "Topic  1\n",
      "brain neuron body memory area animal sleep mind region ability control fly study behavior activity light turn consciousness understand arm\n",
      "Topic  2\n",
      "woman men girl man gender sex boy female young black male violence mother heart women sexual issue men woman daughter job\n",
      "Topic  3\n",
      "country government china africa global percent india economic state political united war economy growth social society money states united states democracy\n",
      "Topic  4\n",
      "water ocean planet earth animal sea fish specie mars surface area ice tree forest coral climate shark percent foot plant\n",
      "Topic  5\n",
      "cell stem stem cell organ body disease dna gene light tissue drug molecule bacteria animal structure technology patient bone virus material\n",
      "Topic  6\n",
      "school kid student teacher education high class money learning teach girl classroom community high school college old learn dollar parent percent\n",
      "Topic  7\n",
      "city building space design street community public project flag built neighborhood architecture new york york water live map urban build house\n",
      "Topic  8\n",
      "technology computer design machine sort information project example using internet building create process company build working phone learning real digital\n",
      "Topic  9\n",
      "universe space black galaxy light star hole planet black hole earth telescope particle image dark theory energy sun matter picture billion\n",
      "Topic  10\n",
      "data information number web using decision company map algorithm government phone looking drug social network percent scientist person example google\n",
      "Topic  11\n",
      "car energy percent dollar oil power cost money company nuclear million business fuel mile le 10 technology solar billion half\n",
      "Topic  12\n",
      "game video play video game real playing player hour online feel win social virtual real world dynamic action try experience future design\n",
      "Topic  13\n",
      "robot body build building animal leg foot video sort rule lab task play motion ant control eye real maybe help\n",
      "Topic  14\n",
      "child family parent baby mother old country year old home autism young school father born language month age girl refugee institution\n",
      "Topic  15\n",
      "story book film tell story told read telling live character movie picture mother narrative wanted moment history medium africa maybe single\n",
      "Topic  16\n",
      "health patient care doctor disease medical community drug hospital medicine health care heart hiv percent help treatment study clinic healthcare mother\n",
      "Topic  17\n",
      "cancer tumor body blood disease drug breast patient cell percent vessel treatment muscle protein doctor lung tissue trial early stage\n",
      "Topic  18\n",
      "play music sound language word example piece hear english instrument voice hand book learn hearing course playing song listen social\n",
      "Topic  19\n",
      "food eat plant ant farmer feed percent animal market colony kid bread eating waste bee le diet fish billion meat\n",
      "\n",
      "NMF done in 15.145s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "vect_mod, vect_data, nmf_mod, nmf_data  = topic_mod_nmf(cleaned_talks,\n",
    "                                                             topics=20,\n",
    "                                                             iters=50,\n",
    "                                                             ngram_min=1, \n",
    "                                                             ngram_max=2, \n",
    "                                                             max_df=0.5, \n",
    "                                                             max_feats=2000)\n",
    "print(\"\\nNMF done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_mod_lsa(data, topics=5,ngram_min=1, ngram_max=3, max_df=0.6, max_feats=5000):\n",
    "    \n",
    "    vectorizer = CountVectorizer(ngram_range=(ngram_min,ngram_max), \n",
    "                             stop_words='english', \n",
    "                             max_df = max_df, \n",
    "                             max_features=max_feats)\n",
    "   \n",
    "    vect_data = vectorizer.fit_transform(data)\n",
    "    lsa = TruncatedSVD(n_components=topics,random_state=42)\n",
    "    lsa_dat = lsa.fit_transform(vect_data)\n",
    "    \n",
    "    def display_topics(model_, feature_names, no_top_words):\n",
    "        for ix, topic in enumerate(model_.components_):\n",
    "            print(\"Topic \", ix)\n",
    "            print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "    \n",
    "    display_topics(lsa, vectorizer.get_feature_names(),20)\n",
    "    \n",
    "    return vectorizer, vect_data, lsa, lsa_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic  0\n",
      "country woman story percent child brain technology school example million course kid number city old data feel sort love maybe\n",
      "Topic  1\n",
      "brain cell light technology body computer animal cancer neuron planet space earth data robot information universe water machine using sort\n",
      "Topic  2\n",
      "brain woman cell men cancer child body girl love patient story disease neuron man mother feel baby heart boy memory\n",
      "Topic  3\n",
      "country cell cancer percent disease brain health patient drug africa data government dollar china growth global blood food market care\n",
      "Topic  4\n",
      "woman water planet cancer earth cell men universe space ocean light energy black star mars galaxy body specie solar sun\n",
      "Topic  5\n",
      "brain country woman planet neuron energy earth men china water universe global africa climate area region power ocean billion economic\n",
      "Topic  6\n",
      "child school kid water food city brain family planet animal ocean earth parent fish mother area old percent plant teacher\n",
      "Topic  7\n",
      "city building brain car design woman street cell architecture public space flag community project built neighborhood men new york york urban\n",
      "Topic  8\n",
      "story cancer country cell love feel war god political book china believe word live body moment experience film animal global\n",
      "Topic  9\n",
      "universe black space city galaxy child hole black hole data star light country image telescope particle building dark patient cancer theory\n",
      "Topic  10\n",
      "data water story car city ocean information health patient fish care child doctor love sea food shark percent baby web\n",
      "Topic  11\n",
      "car dollar energy money game love percent cancer oil kid cost company hour power universe mile guy business solar feel\n",
      "Topic  12\n",
      "game play cancer health city patient robot care doctor video black experience video game social study playing space feel disease medical\n",
      "Topic  13\n",
      "robot car child energy patient care family health power body space oil doctor seat universe cost machine mother leg hospital\n",
      "Topic  14\n",
      "game story child data robot car cell video country play video game family technology city india power playing energy planet light\n",
      "Topic  15\n",
      "robot story kid school data food brain cancer student country black light money play teacher africa dollar black hole hole image\n",
      "Topic  16\n",
      "story design patient health africa building care dollar technology money water business brain community company project doctor cost woman computer\n",
      "Topic  17\n",
      "cancer story language energy book computer student science tumor machine school word power child learning planet percent particle teacher technology\n",
      "Topic  18\n",
      "country cancer car africa computer language word image sound music india black china hole picture black hole piece sort love art\n",
      "Topic  19\n",
      "food story car universe ant animal black plant eat africa example black hole specie hole gene city galaxy farmer colony dna\n",
      "\n",
      "LSA done in 12.910s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "vect_mod, vect_data, lsa_mod, lsa_data  = topic_mod_lsa(cleaned_talks,\n",
    "                                                        topics=20,\n",
    "                                                        ngram_min=1, \n",
    "                                                        ngram_max=2, \n",
    "                                                        max_df=0.5, \n",
    "                                                        max_feats=2000)\n",
    "print(\"\\nLSA done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA + TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_mod_lsa_t(data, topics=5,ngram_min=1, ngram_max=3, max_df=0.6, max_feats=5000):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(ngram_range=(ngram_min,ngram_max), \n",
    "                             stop_words='english', \n",
    "                             max_df = max_df, \n",
    "                             max_features=max_feats)\n",
    "    \n",
    "    vect_data = vectorizer.fit_transform(data)\n",
    "    stdScale = Normalizer()\n",
    "    vect_scale = stdScale.fit_transform(vect_data)\n",
    "    lsa_t = TruncatedSVD(n_components=topics,random_state=42)\n",
    "    lsa_t_dat = lsa_t.fit_transform(vect_scale)\n",
    "    \n",
    "    def display_topics(model_, feature_names, no_top_words):\n",
    "        for ix, topic in enumerate(model_.components_):\n",
    "            print(\"Topic \", ix)\n",
    "            print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "    \n",
    "    display_topics(lsa_t, vectorizer.get_feature_names(),20)\n",
    "    \n",
    "    return vectorizer, vect_data, lsa_t, lsa_t_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic  0\n",
      "woman child story country city brain technology kid percent school love data water feel family design community word old sort\n",
      "Topic  1\n",
      "woman men girl child school country family story kid mother boy father young man war violence parent education love community\n",
      "Topic  2\n",
      "city country government percent global africa economy dollar climate water energy china company building market money business economic billion oil\n",
      "Topic  3\n",
      "cancer cell patient brain disease drug health percent country doctor gene woman data tumor treatment medical medicine care blood hiv\n",
      "Topic  4\n",
      "woman water ocean planet earth animal sea specie fish men plant ice forest mars tree coral universe energy girl light\n",
      "Topic  5\n",
      "city kid school cancer building design patient child cell teacher community neighborhood car architecture disease doctor health project student food\n",
      "Topic  6\n",
      "kid school child teacher student education ocean food learning classroom parent water fish planet africa teach teaching percent learn grade\n",
      "Topic  7\n",
      "brain city neuron music mind sound country language love food feel child memory word mental democracy god war compassion area\n",
      "Topic  8\n",
      "brain robot woman city neuron child men school girl machine education building student kid car energy teacher animal learning area\n",
      "Topic  9\n",
      "robot animal music fish ocean war water leg sea forest story coral specie body song plant foot play shark food\n",
      "Topic  10\n",
      "robot universe patient galaxy star planet space earth city telescope mars cancer particle war sun doctor solar health care child\n",
      "Topic  11\n",
      "data car brain ocean patient company water guy mile hour care vehicle phone health doctor love percent hospital sea dollar\n",
      "Topic  12\n",
      "music sound woman play song energy instrument car hear dollar playing percent string economy business market growth company cost piece\n",
      "Topic  13\n",
      "data music ocean city child sound information health map patient fish sea image africa video community coral water animal shark\n",
      "Topic  14\n",
      "design patient health art building care designer object africa architecture hospital medical happiness doctor artist project woman experience water material\n",
      "Topic  15\n",
      "africa brain country cell light image child story phone war african india film device art aid camera government father neuron\n",
      "Topic  16\n",
      "ocean cancer game school student teacher sea video coral fish brain government kid cell education tumor shark play democracy ice\n",
      "Topic  17\n",
      "cancer language book word english art story car image china artist africa robot india tumor city oil painting country student\n",
      "Topic  18\n",
      "water energy machine nuclear technology power climate cancer language child democracy voice sound word fuel war oil english coal carbon\n",
      "Topic  19\n",
      "game machine technology video child car computer cancer animal baby africa video game dna city play specie object camera player digital\n",
      "\n",
      "LSA_T done in 12.733s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "vect_mod, vect_data, lsa_t_mod, lsa_t_data  = topic_mod_lsa_t(cleaned_talks,\n",
    "                                                              topics=20,\n",
    "                                                              ngram_min=1, \n",
    "                                                              ngram_max=2, \n",
    "                                                              max_df=0.5, \n",
    "                                                              max_feats=2000)\n",
    "print(\"\\nLSA_T done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the above topics and the words they are comprised of, we can observe that LDA performs the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_ind = np.argmax(lda_data, axis=1)\n",
    "topic_labels = pd.DataFrame(topic_ind)\n",
    "topic_names = topic_labels\n",
    "topic_names[topic_names==0] = \"marine\"\n",
    "topic_names[topic_names==1] = \"writing\"\n",
    "topic_names[topic_names==2] = \"disease biology\"\n",
    "topic_names[topic_names==3] = \"story\"\n",
    "topic_names[topic_names==4] = \"human body\"\n",
    "topic_names[topic_names==5] = \"education\"\n",
    "topic_names[topic_names==6] = \"nature\"\n",
    "topic_names[topic_names==7] = \"architecture\"\n",
    "topic_names[topic_names==8] = \"technology, medium\"\n",
    "topic_names[topic_names==9] = \"family\"\n",
    "topic_names[topic_names==10] = \"build\"\n",
    "topic_names[topic_names==11] = \"medicine\"\n",
    "topic_names[topic_names==12] = \"global economy\"\n",
    "topic_names[topic_names==13] = \"technology, energy\"\n",
    "topic_names[topic_names==14] = \"politics\"\n",
    "topic_names[topic_names==15] = \"medicine\"  \n",
    "topic_names[topic_names==16] = \"social\"\n",
    "topic_names[topic_names==17] = \"animal\"\n",
    "topic_names[topic_names==18] = \"market\"\n",
    "topic_names[topic_names==19] = \"space\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve similar documents using NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simi(first_article,num_of_recs,topics,ted_data, model, vectorizer, training_vectors):\n",
    "    \n",
    "    new_vec = model.transform(\n",
    "        vectorizer.transform([first_article]))\n",
    "    \n",
    "    nn = NearestNeighbors(n_neighbors=num_of_recs, metric='cosine', algorithm='brute')\n",
    "    nn.fit(training_vectors)\n",
    "    \n",
    "    results = nn.kneighbors(new_vec)\n",
    "    \n",
    "    recommend_list = results[1][0]\n",
    "    scores = results[0]\n",
    "                       \n",
    "    ss = np.array(scores).flat       \n",
    "    for i, resp in enumerate(recommend_list):\n",
    "        print('\\nID: ', + resp)\n",
    "        print('Cosine Distance: ', + ss[i])  \n",
    "        print('Topics: ' + topics.iloc[resp,0])\n",
    "        print('URL: ' + ted_data.iloc[resp,1])\n",
    "        print(\"TED's original tags: \")\n",
    "        print(ted_data.iloc[resp,-3])\n",
    "        print(\"\\n------------------------\")\n",
    "        \n",
    "    return recommend_list, ss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ID:  804\n",
      "Cosine Distance:  2.220446049250313e-16\n",
      "Topics: human body\n",
      "URL: https://www.ted.com/talks/charles_limb_your_brain_on_improv\r\n",
      "\n",
      "TED's original tags: \n",
      "Your brain on improv\n",
      "\n",
      "------------------------\n",
      "\n",
      "ID:  1907\n",
      "Cosine Distance:  0.029006092710062714\n",
      "Topics: medicine\n",
      "URL: https://www.ted.com/talks/laura_schulz_the_surprisingly_logical_minds_of_babies\r\n",
      "\n",
      "TED's original tags: \n",
      "The surprisingly logical minds of babies\n",
      "\n",
      "------------------------\n",
      "\n",
      "ID:  602\n",
      "Cosine Distance:  0.046728506250262036\n",
      "Topics: medicine\n",
      "URL: https://www.ted.com/talks/pawan_sinha_on_how_brains_learn_to_see\r\n",
      "\n",
      "TED's original tags: \n",
      "How brains learn to see\n",
      "\n",
      "------------------------\n",
      "\n",
      "ID:  1488\n",
      "Cosine Distance:  0.05830870117550302\n",
      "Topics: human body\n",
      "URL: https://www.ted.com/talks/steve_ramirez_and_xu_liu_a_mouse_a_laser_beam_a_manipulated_memory\r\n",
      "\n",
      "TED's original tags: \n",
      "A mouse. A laser beam. A manipulated memory.\n",
      "\n",
      "------------------------\n",
      "\n",
      "ID:  1752\n",
      "Cosine Distance:  0.06126162343640251\n",
      "Topics: medicine\n",
      "URL: https://www.ted.com/talks/nancy_kanwisher_the_brain_is_a_swiss_army_knife\r\n",
      "\n",
      "TED's original tags: \n",
      "A neural portrait of the human mind\n",
      "\n",
      "------------------------\n",
      "\n",
      "ID:  1044\n",
      "Cosine Distance:  0.06331054700040117\n",
      "Topics: human body\n",
      "URL: https://www.ted.com/talks/antonio_damasio_the_quest_to_understand_consciousness\r\n",
      "\n",
      "TED's original tags: \n",
      "The quest to understand consciousness\n",
      "\n",
      "------------------------\n",
      "\n",
      "ID:  2122\n",
      "Cosine Distance:  0.06562758311108763\n",
      "Topics: medicine\n",
      "URL: https://www.ted.com/talks/uri_hasson_this_is_your_brain_on_communication\r\n",
      "\n",
      "TED's original tags: \n",
      "This is your brain on communication\n",
      "\n",
      "------------------------\n",
      "\n",
      "ID:  2195\n",
      "Cosine Distance:  0.07191643205195974\n",
      "Topics: medicine\n",
      "URL: https://www.ted.com/talks/david_camarillo_why_helmets_don_t_prevent_concussions_and_what_might\r\n",
      "\n",
      "TED's original tags: \n",
      "Why helmets don't prevent concussions -- and what might\n",
      "\n",
      "------------------------\n",
      "\n",
      "ID:  2406\n",
      "Cosine Distance:  0.07566472948618697\n",
      "Topics: human body\n",
      "URL: https://www.ted.com/talks/anil_seth_how_your_brain_hallucinates_your_conscious_reality\r\n",
      "\n",
      "TED's original tags: \n",
      "Your brain hallucinates your conscious reality\n",
      "\n",
      "------------------------\n",
      "\n",
      "ID:  151\n",
      "Cosine Distance:  0.08425104333910316\n",
      "Topics: medicine\n",
      "URL: https://www.ted.com/talks/vilayanur_ramachandran_on_your_mind\r\n",
      "\n",
      "TED's original tags: \n",
      "3 clues to understanding your brain\n",
      "\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "rec_list, scores = get_simi(cleaned_talks[804],10, topic_names, ted_all,\n",
    "                                       lda_mod, vect_mod, lda_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
