{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import argparse\n",
    "import codecs\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "\"\"\"\n",
    "This file is part of the computer assignments for the course DD1418/DD2418 Language engineering at KTH.\n",
    "Created 2018 by Johan Boye and Patrik Jonell.\n",
    "\"\"\"\n",
    "\n",
    "class Generator(object) :\n",
    "    \"\"\"\n",
    "    This class generates words from a language model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "    \n",
    "        # The mapping from words to identifiers.\n",
    "        self.index = {}\n",
    "\n",
    "        # The mapping from identifiers to words.\n",
    "        self.word = {}\n",
    "\n",
    "        # An array holding the unigram counts.\n",
    "        self.unigram_count = {}\n",
    "\n",
    "        # The bigram log-probabilities.\n",
    "        self.bigram_prob = defaultdict(dict)\n",
    "\n",
    "        # Number of unique words (word forms) in the training corpus.\n",
    "        self.unique_words = 0\n",
    "\n",
    "        # The total number of words in the training corpus.\n",
    "        self.total_words = 0\n",
    "\n",
    "        # The average log-probability (= the estimation of the entropy) of the test corpus.\n",
    "        # Important that it is named self.logProb for the --check flag to work\n",
    "        self.logProb = 0\n",
    "\n",
    "        # The identifier of the previous word processed in the test corpus. Is -1 if the last word was unknown.\n",
    "        self.last_index = -1\n",
    "\n",
    "        # The fraction of the probability mass given to unknown words.\n",
    "        self.lambda3 = 0.000001\n",
    "\n",
    "        # The fraction of the probability mass given to unigram probabilities.\n",
    "        self.lambda2 = 0.01 - self.lambda3\n",
    "\n",
    "        # The fraction of the probability mass given to bigram probabilities.\n",
    "        self.lambda1 = 0.99\n",
    "\n",
    "        # The number of words processed in the test corpus.\n",
    "        self.test_words_processed = 0\n",
    "\n",
    "\n",
    "    def read_model(self,filename):\n",
    "        \"\"\"\n",
    "        Reads the contents of the language model file into the appropriate data structures.\n",
    "\n",
    "        :param filename: The name of the language model file.\n",
    "        :return: <code>true</code> if the entire file could be processed, false otherwise.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            with codecs.open(filename, 'r', 'utf-8') as f:\n",
    "                self.unique_words, self.total_words = map(int, f.readline().strip().split(' '))\n",
    "                # REUSE YOUR CODE FROM BigramTester.py here\n",
    "                return True\n",
    "        except IOError:\n",
    "            print(\"Couldn't find bigram probabilities file {}\".format(filename))\n",
    "            return False\n",
    "\n",
    "    def generate(self, w, n):\n",
    "        \"\"\"\n",
    "        Generates and prints n words, starting with the word w, and following the distribution\n",
    "        of the language model.\n",
    "        \"\"\" \n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Parse command line arguments\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='BigramTester')\n",
    "    parser.add_argument('--file', '-f', type=str,  required=True, help='file with language model')\n",
    "    parser.add_argument('--start', '-s', type=str, required=True, help='starting word')\n",
    "    parser.add_argument('--number_of_words', '-n', type=int, default=100)\n",
    "\n",
    "    arguments = parser.parse_args()\n",
    "\n",
    "    generator = Generator()\n",
    "    generator.read_model(arguments.file)\n",
    "    generator.generate(arguments.start,arguments.number_of_words)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
